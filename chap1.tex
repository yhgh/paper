\chapter{绪论}
\section{研究背景与意义}
随着人类对太空探索的不断深入，越来越多的航天器被送入地球轨道，用于通信、导航、遥感、空间实验等多种任务\cite{prol2022position,zhao2022overview,nozawa2023extent}。与此同时，故障或废弃卫星、火箭上面级以及其他空间碎片在轨数量快速增长，已对正常运行的航天器构成潜在威胁，空间残骸问题日益严峻\cite{debris1,debris2}。为应对这一问题，在轨服务（On-Orbit Servicing, OOS）\cite{ma2023advances,nwac129,asri2024introductory,wang2023bridging}与在轨残骸清除(Active Debris Removal，ADR)成为研究热点\cite{BARANOV2024100982,CREASER2024481,BAREA20243060,WANG2025}。如图~\ref{fig:OOS_ADR}所示，左边的场景为一个追踪者航天器捕获一个卫星从而进行维修操作，比如在轨零件更换，在轨燃料加注等。而右边的场景为一个追踪者航天器捕获一个火箭引擎残骸进而进行清理操作。为了完成上述两类任务，通常需要首先获取目标航天器或空间物体的6D姿态，进而完成目标捕获过程中的近进和捕获操作。然而，空间环境中的一些复杂条件\cite{aerospace10120997}，以及目标在轨的非合作的特性\cite{PAULY2023339}，以及某些目标存在较为特殊的几何外形，这些使得6D姿态测量手段面临较大挑战。
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{Img/OOS_ADR.png}
	\caption{OOS与ADR的场景}
	\label{fig:OOS_ADR}
\end{figure}

\section{研究现状}
\subsection{在轨目标位姿测量技术}
如图~\ref{fig:6D_equip}所示，从6D姿态测量的各种设备方案来看主要有单目相机\cite{PAULY2023339, 9802504,Zhang_2024_CVPR,Liu_2024_CVPR}、双目相机\cite{GXXB202106018, zhang2017optimization,Fan2024}、结构光\cite{laser_stereo,hu2023non,sun2022relative}和激光雷达\cite{10801205,10823741}。双目相机，结构光，激光雷达这些方案能够获取目标额外的深度信息，理论上更有利于进行目标的6D姿态估计。但是从设备本身来说，这些设备的复杂度要明显高于单目相机，硬件的可靠性相对较差，同时成本也高于单目相机。从空间的环境干扰来说，由于空间中存在极端的光照环境，使得双目相机，结构光，激光雷达这些对光照条件要求较为苛刻的测量手段会受到干扰\cite{rs15092286,tian2023all}。相比之下，基于单目视觉的方案仅需一台相机，设备简单，可靠性高，成本较低，在航天器上易于部署。同时对于极端光照条件较为鲁棒的单目图像处理算法的研究更为丰富。因此，单目视觉6D姿态估计正成为在轨服务领域的重要研究方向。然而，单目相机仅能获取目标的二维图像信息，缺少直接的深度测量。加之空间环境下光照剧变、弱纹理和高亮背景等复杂因素，往往进一步降低了特征提取和匹配的稳定性\cite{Hu_2021_CVPR,wang2022revisiting}。如何在保证硬件系统简单的前提下，克服单目视觉对深度信息依赖的先天不足，以及空间环境中光照与纹理不利条件带来的精度衰减，依旧是一个亟待解决的难题。
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{Img/6Dpose_measure_equipment.png}
	\caption{6D姿态测量设备方案}
	\label{fig:6D_equip}
\end{figure}
\subsection{基于深度学习的位姿估计}
在地面场景中，单目6D位姿估计已被广泛研究，并催生了多种成熟算法与应用。近年来，深度学习技术的引入为该领域带来了快速发展，一些工作采用了直接回归或端到端的方式输出目标的 6D 姿态，如 DOPE \cite{Tekin2018DOPE}、DPOD \cite{Li2019DPOD}、GDR-Net \cite{Wang2021GDRNet} 与 CosyPose \cite{Peng2020CosyPose6D} 等。这类方法在一定程度上简化了特征匹配流程，但在面对纹理缺乏或光照变化时，模型往往需要更丰富的训练数据以及复杂的网络结构来保证鲁棒性。
也有关键点检测 + PnP的思路，通过检测图像关键点并与目标先验模型匹配后，再使用 PnP 算法（如 P3P、EPnP）估计位姿。该类方案结合了深度学习对特征的鲁棒提取能力与几何算法的可解释性，可以结合 RANSAC 等机制可有效剔除异常点。是相对来说更为准确的检测思路，但对于检测关键点，目前来说主要有两类

在航天应用中，一些研究也在探索如何在弱纹理与强光照干扰下实现准确的关键点检测，如文献 \cite{Landrieu2018PointFusion, Simon2018BB8} 等在多模态融合与局部特征学习方面做出了探索。
融合Transformer和检测网络亦是近来的研究趋势，如 End-to-End Object Detection with Transformers（DETR）\cite{Carion2020EndToEnd} 将目标检测过程简化为一个序列预测任务；Pyramid Vision Transformer（PVT）\cite{Wang2021PyramidVisionTransformer} 借助金字塔结构缓解了高分辨率特征图带来的大规模计算，并适用于包括目标检测、语义分割等在内的多种视觉任务；对于人脸关键点与空间目标关键点检测，Sparse Local Patch Transformer \cite{Xia2022SparseLocalPatch} 展示了在局部特征聚合和注意力学习方面的潜力。
此外，DenseFusion \cite{Wang2019DenseFusion6D} 与 PointFusion \cite{Landrieu2018PointFusion} 等工作还探讨了 传感器数据融合（RGB + 深度）以增强 6D 姿态估计的鲁棒性。
针对在轨航天器的自身芯片的算力限制以及对可靠性的要求，以上方法在地面场景的成功经验并不能直接迁移，更常用的还是单目，或者稍微复杂一点的双目，激光雷达系统结合一定的传统算法进行求解。
\subsection{卡尔曼滤波在航天领域的应用}
卡尔曼滤波（Kalman Filter，KF）自 20 世纪 60 年代由 Kalman~\cite{kalman1960new} 提出以来，一直是信号处理和状态估计领域的里程碑式算法。最初的线性 KF 假设系统模型呈线性、高斯噪声分布且统计特性已知，虽然在当时已成功应用于导弹制导、姿态控制等工程项目，但随着日后应用环境的复杂化与非线性化需求迅猛增长，单纯的线性 KF 很快在处理强非线性与未知噪声特性等问题时力不从心。为此，研究者开始借助扩展卡尔曼滤波（Extended Kalman Filter，EKF）~\cite{jazwinski2007stochastic} 对系统方程进行一阶泰勒展开，从而在一定程度上提升了对非线性系统的适应能力。得益于 EKF 的出现，卡尔曼滤波在航天器姿态确定方面取得了早期成功，例如 NASA 在阿波罗登月计划中所使用的导航计算机亦借鉴了 KF 的思想来处理惯性导航数据。不过，EKF 在面对显著非线性或高速翻滚状态时，易受线性化近似误差的影响而出现滤波发散或精度衰减的问题。

为克服 EKF 在强非线性系统中的局限，Julier 与 Uhlmann 在 1990 年代提出了无迹变换（Unscented Transform）及无迹卡尔曼滤波（Unscented Kalman Filter，UKF）~\cite{Julier1997}。UKF 通过精心选取的 Sigma 点来捕捉非线性系统中均值与协方差传播的演化过程，相较于 EKF 无需显式求解雅可比矩阵，且在高翻滚速度或强耦合动力学中能更稳定地保持估计精度。与此同时，Particle Filter（PF）与容积卡尔曼滤波（Cubature Kalman Filter，CKF）等算法也相继出现，它们或通过基于蒙特卡洛采样的粒子群对任意分布进行近似，或借助容积积分公式提升在多维系统中的精度，进一步丰富了非线性滤波在复杂航天任务场景下的选择~\cite{9272767,AMCCKF_2023}。

近年来，卡尔曼滤波及其改进算法在航天领域（尤其是非合作目标的视觉测量与在轨服务等任务）得到了广泛应用。对于航天器姿态确定这一核心任务，早期方法多采用 EKF 直接对非线性姿态运动方程进行局部线性化~\cite{Lefferts1982,Shuster1981}；然而在强耦合、高翻滚速度以及柔性附件效应下，EKF 往往容易在精度或数值稳定性上失效。为提升非线性捕捉能力与鲁棒性，越来越多研究者开始基于 UKF 或 PF 等算法进行姿态滤波：相较之下，UKF 依托无迹变换能够更准确地捕捉姿态动力学中均值与协方差的传播特征，对高速翻滚或带有柔性部件的航天器具有更高的姿态估计精度和稳定性~\cite{NJHK202201006,1024861534.nh}。另外，诸如自适应策略（噪声协方差在线辨识）、最大相关熵（Maximum Correntropy Criterion）或变分贝叶斯（Variational Bayesian）等思想在卡尔曼滤波基础上的结合，使得算法在存在非高斯噪声、传感器故障以及系统建模误差等恶劣条件下依然能维持较高精度与收敛速度~\cite{GXJM202103017,9272767,qiu2023novel,POURTAKDOUST2022134}。

对于非合作目标的视觉导航与姿态估计，这一问题在当前在轨服务（On-Orbit Servicing，OOS）及主动清除（Active Debris Removal，ADR）任务中尤为突出。由于缺乏先验的外形、惯性参数以及可用的星敏感器或激光角度测距等协作信号，需要完全依赖外部视觉传感器（如激光雷达、双目/多目相机等）进行相对姿态与位置的量测。文献~\cite{BARBIER2023144} 在误差状态卡尔曼滤波（ESKF）框架下引入对目标形状和动力学模型的联合估计，并借助高斯过程（Gaussian Processes）来对目标旋转进行建模，成功在合成视觉数据中实现了对未知目标形状与运动的准确跟踪。除此之外，在推力脉冲或陀螺故障的场景下，量测分布往往呈现非高斯性或存在尖峰、拖尾等异常噪声特征，基于高斯混合模型（GMM）、相关熵或实时协方差匹配的自适应滤波方案便可以有效应对短时或者突发误差。例如，文献~\cite{2022HO-UKF} 提出了运用高阶 UKF 对多传感器（太阳敏感器、磁强计等）观测融合的策略，降低了航天器姿态确定对单一测量的依赖；而文献~\cite{kim2023gmm,Xiao_2024,AMCCKF_2023} 进一步提出针对测量噪声分布随时间变化或存在离群点时的自适应调参与鲁棒优化方法，从而在系统与量测模型不匹配时依然能维持良好性能。与此同时，故障检测与隔离（FDI）机制在滤波流程中的嵌入，也为高可靠度的姿态控制打下基础~\cite{POURTAKDOUST2022134}。


\section{空间非合作目标6D姿态估计面临的问题与挑战}
\label{sec:problems_challenges}

在空间在轨服务与空间交会捕获等应用场景中，精确获取空间非合作目标的六自由度（6D）位姿信息具有重要意义。然而，这一任务在实际应用中面临诸多挑战。首先，效率、精度与成本的兼顾难题尤为突出。传统的深度测量手段如双目相机、结构光和激光雷达，虽然在深度获取和空间分辨率方面具有优势，但其系统复杂度高、功耗大且维护成本高，限制了其在大规模航天任务中的应用。相比之下，单目相机因其结构简单、重量轻、功耗低，成为更具潜力的选择。然而，单目相机仅能获取目标的二维图像投影，缺乏直接的深度信息，对算法端的深度推断和姿态解算提出了更高的要求。

其次，不同网络模型形式在速度与精度之间的权衡也是一个关键问题。基于密集预测（热图）的深度学习网络通常能够在关键点定位上取得较高的精度，但其计算量和推理成本较高，不利于在资源受限的空间平台上实时部署。相比之下，端到端的直接回归模型具有更高的推理速度和更低的计算资源需求，但在关键点定位的精度上往往不及密集预测方法。这种效率与精度之间的权衡，使得在空间非合作目标6D姿态估计中，如何选择合适的网络架构成为一个亟待解决的问题。

此外，空间非合作目标的运动估计复杂性也是一个重要挑战。由于目标通常处于失控状态，且与追踪者航天器之间缺乏交互，只能依赖单目视觉获取的图像序列进行位姿估计。目标可能以未知且复杂的翻滚方式在三维空间中运动，且其表面可能缺乏明显的纹理或特征点，甚至在某些姿态下出现明亮背景、反射光斑或部分遮挡。这些因素大大增加了视觉检测的难度，对算法的鲁棒性和跟踪能力提出了更高的要求。如何在这种复杂环境下，通过单目图像序列有效地结合目标的运动信息，实现深度与姿态的准确重建，是当前研究的重点难题。

最后，在轨实时性与鲁棒性之间的平衡也是一个关键问题。空间任务通常要求在较短时间内完成精确的姿态估计，以便进行后续的操作决策。然而，空间环境中的计算资源有限，传统高精度的视觉算法往往依赖于高性能的计算平台，这在实际空间应用中难以实现。同时，外界干扰如强光照差、地球背景辐射和宇宙粒子等因素，可能导致传感器噪声和关键点漏检，进而影响姿态估计的稳定性和准确性。因此，如何设计既具备高效率又能在复杂干扰环境下保持鲁棒性的姿态估计算法，成为推动空间非合作目标6D姿态估计技术发展的重要方向。

综上所述，空间非合作目标6D姿态估计在效率、精度、成本与可靠性等多方面面临严峻挑战。为此，研究者们需要从硬件系统简化、深度学习模型设计、几何优化方法提升、传感器数据融合以及时序滤波与控制策略等多个维度进行深入探索，以期在复杂的空间环境中实现高效、精确且可靠的姿态估计。
\section{论文的组织结构}
第一章绪论阐述了空间非合作目标6D姿态估计的背景和意义，介绍了相关研究现状与主要技术路线，并明确提出本文的研究目标与整体思路。

第二章理论基础介绍了6D姿态的概念及其数学表示方法，相机模型，PnP问题与常见解法，概述注意力机制与卡尔曼滤波的基础理论，为后续章节提供必要的理论支撑。

第三章到第五章介绍了空间非合作目标6D姿态估计的整体流程，如图\ref{fig:6D_pose_estimation_archieture}所示，对于一张空间非合作目标单图像i，输入基于注意力机制的关键点检测网络，得到图像i的空间非合作目标的像素坐标，然后结合空间非合作目标标注6D姿态的关键点3D坐标输入到RANSAC-TRO SQPnP来解算出图像i的空间非合作目标6D姿态，为了进一步提升6D姿态估计的精度，按时序输入基于关键点观测的SE(3) EKF滤波器得到滤波后的空间非合作目标6D姿态估计结果。

具体而言第三章，依次介绍了空间非合作目标关键点检测数据集的构建，包括公开数据集SPEED与SPEED+的关键点标注，以及Nauka MLM与Starlink数据集的渲染和关键点标注。然后介绍了在YOLOv8-  Pose架构的基础上， 用轻量化的Transformer EfficientViT 与 Triplet Attention 分别改进了YOLOv8 -Pose骨干网络， YOLOv8-Pose的Neck网络，构建出了一个兼顾效率和精度的关键点检测模型用以预测出单目图像中关键点的像素坐标，其中EfficientViT与Triplet Attention像增强了模型对空间非合作目标图像的特征提取能力和鲁棒性。为了增强模型应对3D目标的变化的收敛精度，利用了小孔成像模型在OKS（Object Keypoint Similarity）损失的基础上提出了A3DKS损失，利用该损失有效的训练出了更高精度的关键点检测模型。以上的改进均通过了消融实验验证了改进的有效性。

而第四章介绍了RANSAC-TRO SQPnP算法， 利用该算法在求出的关键点的像素坐标的基础上进行6D姿态的解算，从而得出了单目图像中空间非合作目标的6D姿态。同时也把从本文提出的方法（第三章到第四章）的估计结果的精度与其他单目图像6D姿态估计的方法进行了对比从而验证了本文提出方法的有效性。

第五章考虑到某些场景中仍存在6D姿态估计误差异常大的案例，本文深入分析了空间非合作目标的运动特性，采用了EKF对空间非合作目标进行6D姿态滤波，但是由于空间非合作目标运动的姿态变化的非线性引入了SE(3)的四元数及第三章预测出的关键点为观测量，有效地提高了EKF滤波的精度。


第六章总结与展望总结了全文的研究贡献，指出论文的不足之处，并展望未来在轨目标视觉测量与服务技术的发展方向。

\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{Img/chapt2_overview.png}
	\caption{本文的方法架构}
	\label{fig:6D_pose_estimation_archieture}
\end{figure}
