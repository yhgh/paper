%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-
\maketitle % 生成中文封面
\MAKETITLE % 生成英文封面
%-\maketitle  % 生成英文封面
%-
%-> 作者声明
%-
% committee.pdf 只有 1 页，
% 我们先取它的第 1 页，再跟一张空白页
\includepdf[
pages={{},1},        % 1 → 源 PDF 第 1 页；{} → 空白页
pagecommand={\thispagestyle{empty}} % 让插入页不带页眉页脚
]{C:/Users/PC/Desktop/20250315/committee.pdf}

\makedeclaration % 生成声明页
%-
%-> 中文摘要
%-

\intotoc\chapter*{摘\qquad 要}% 显示在书签，目录,3.0修改2汉字字符间距
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号
随着人类空间活动的日益频繁，轨道上的故障航天器和空间残骸不断增多，不仅占用在轨资源，也对在轨航天器构成潜在威胁。对这些故障航天器进行维修并清理空间残骸已成为当前的迫切需求，而准确获取空间目标的 6D 姿态信息是实现上述任务的关键。然而，此类目标通常属于空间非合作目标，缺乏容易利用的特征标志或交互手段。再加上空间环境与目标本身的复杂性，使得空间非合作目标的 6D 姿态估计面临诸多挑战。

为有效解决上述难题，本文提出了一种基于单目图像关键点检测的空间非合作目标 6D 姿态估计方法。主要工作包括：设计了一种基于注意力机制改进的关键点检测网络；提出了一种鲁棒的 6D 姿态解算方法；改进了适应非线性运动的 6D 姿态滤波方法。具体内容如下：

（1）针对网络轻量化与精度的平衡问题，本文在 YOLOv8 架构的基础上融合了 Efficient Vision Transformer（EfficientViT）和 Triplet Attention 模块，构建了兼顾较高精度与轻量化的关键点检测网络。针对关键点的 3D 特性，本文结合针孔相机原理，在 YOLOv8 损失函数的基础上，提出了近似 3D 尺度关键点相似度（Approximate 3D Keypoint Similarity，A3DKS）损失函数。在多个数据集上的验证表明，该网络的关键点总体平均像素误差被控制在 7.82 像素至 10.83 像素之间。消融实验的结果表明，SPEED+ 数据集上的 6D 姿态估计误差总指标$\mathrm{score}^+$进一步降低。

（2）针对关键点检测网络预测的关键点噪声对 6D 姿态解算的干扰问题，本文采用了基于重投影误差优化的思路，构造了 RANSAC-TRO SQPnP 算法。该算法首先通过随机采样一致性（Random Sample Consensus，RANSAC）算法排除异常点，获取内点集，然后在内点集上利用 Sequential Quadratic Programming for the Perspective-n-Point（SQPnP）算法进行重投影误差优化得到初步的 6D 姿态参数，最后通过信赖域优化（Trust Region Optimization，TRO）进行精细调整，得到最终的 6D 姿态解算结果。在 SPEED+ 数据集上的实验表明，结合（1）中的方法，RANSAC-TRO SQPnP 解算所得的 6D 姿态，其旋转误差为 1.0760°，绝对平移误差为 0.0459 m，性能优于近年来多种同类方法。

（3）针对空间非合作目标自由翻滚运动过程中的 6D 姿态滤波难题，本文采用了基于关键点观测的 SE(3) 扩展卡尔曼滤波器（Extended Kalman Filter，EKF）。考虑到目标角速度按照欧拉方程演化的复杂性，本文将关键点检测网络输出的关键点作为 EKF 的观测向量，为滤波器提供更丰富的信息以校正估计。在多组模拟空间自由翻滚目标的测试数据上，上述方案将 SPEED 数据集上的 6D 姿态误差的综合指标 $\mathrm{score}$ 均值降低至 0.0230，相比传统 EKF 滤波方案误差减少了 18.7\%。

综上所述，本文在现有 6D 姿态估计方法的基础上，提出了一种针对空间非合作目标的 6D 姿态估计算法。该算法既考虑了轻量化设计，又兼顾了较高的精度，并借助卡尔曼滤波，充分利用目标的运动信息对结果进行平滑，提高了 6D 姿态估计的整体精度。该方法在轨道服务与空间残骸清理等任务中具有潜在的应用价值。



\keywords{6D 姿态估计；空间非合作目标；关键点检测；PnP 问题；卡尔曼滤波}% 中文关键词
%-
%-> 英文摘要
%-
\intotoc\chapter*{Abstract}% Display in bookmarks and table of contents
\setcounter{page}{1}% Starting page number
\pagenumbering{Roman}% Page numbering style
With the increasing frequency of human space activities, the population of failed on-orbit spacecraft and space debris continues to rise. These objects not only occupy valuable orbital resources but also pose potential threats to operational spacecraft. On-orbit servicing (OOS) and active debris removal (ADR) missions have therefore become urgent demands, and accurate acquisition of a object's  6D pose is the key enabler for such tasks. However, most of these objects are non-cooperative; they lack fiducial markers or interactive devices that could facilitate pose estimation. The complexity of the space environment and of the objects themselves further compounds the difficulty of 6D pose estimation for non-cooperative objects.

To effectively resolve the aforementioned challenges, this paper proposes a monocular-image-based keypoint-detection method for 6D pose estimation of non-cooperative space targets. The main efforts encompass the design of an attention-enhanced keypoint detection network, the development of a robust 6D pose-solving method, and the refinement of a 6D pose filtering technique tailored to nonlinear target motion; the specific contributions are detailed below:

(1) To balance model compactness and accuracy, an Efficient Vision Transformer (EfficientViT) and a Triplet Attention module are incorporated into the YOLOv8 backbone, yielding a keypoint detector with both high precision and low computational cost.  
Considering the three-dimensional nature of keypoints, an Approximate 3D Keypoint Similarity (A3DKS) loss is introduced, derived from the pinhole camera model and appended to the original YOLOv8 loss. Experiments on multiple datasets show that the mean pixel error of the detected keypoints is confined to 7.82 pixels to 10.83 pixels. Ablation studies further indicate that the proposed network reduces the overall 6D pose metric $\mathrm{score^+}$ on the SPEED+ dataset.

(2) To mitigate the influence of noise in the detected keypoints, a pose solver named RANSAC-TRO SQPnP is devised. The algorithm first employs Random Sample Consensus (RANSAC) to reject outliers and obtain an inlier set, then applies Sequential Quadratic Programming for the Perspective-n-Point (SQPnP) to minimize the reprojection error and acquire an initial pose. Finally, Trust Region Optimization (TRO) is invoked for fine adjustment. On the SPEED+ dataset, and in conjunction with the first contribution, the solver achieves a rotation error of $1.0760^{\circ}$ and an absolute translation error of $0.0459\,\text{m}$, outperforming several recent state-of-the-art methods.

(3) For free-tumbling non-cooperative objects, a keypoint-aided $\mathrm{SE}(3)$ Extended Kalman Filter (EKF) is formulated. Because the object’s angular velocity obeys Euler’s rotational equations, the detected keypoints serve as the observation vector, furnishing richer information for state correction. On synthetic tumbling sequences, the proposed filter reduces the mean comprehensive metric $\mathrm{score}$ on the SPEED dataset to 0.0230, an 18.7 \% improvement over a conventional EKF.

In summary, this paper introduces a 6D pose-estimation pipeline for non-cooperative space objects that simultaneously pursues lightweight design and high accuracy. By integrating Kalman filtering, the proposed method exploits object kinematics to smooth the results and enhances overall pose accuracy, demonstrating potential applicability to on-orbit servicing and space-debris removal missions.


\KEYWORDS{6D pose estimation; Non-cooperative space objects; Keypoint detection; Perspective-n-Point Problem; Kalman filtering}% 英文关键词
%---------------------------------------------------------------------------%
